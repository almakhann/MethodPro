type="regression",
ntree=100,
do.trace=F)
checkData(rf)
###RandomForest
rf <- randomForest(SalePrice ~ . , train,
type="classification",
ntree=100,
do.trace=F)
checkData(rf)
train
###RandomForest
rf <- randomForest(SalePrice ~., train,
type="classification",
ntree=100,
do.trace=F)
checkData(rf)
rf1 <- randomForest(SalePrice ~ . , train,
type="regression",
ntree=100,
do.trace=F)
checkData(rf1)
saveData(rf)
###RandomForest
rf <- randomForest(SalePrice ~., train,
type="classification",
ntree=100,
do.trace=F)
checkData(rf)
rf1 <- randomForest(SalePrice ~ . , train,
type="regression",
ntree=100,
do.trace=F)
checkData(rf1)
###RandomForest
rf <- randomForest(SalePrice ~., train,
type="classification",
ntree=1000,
do.trace=F)
checkData(rf)
saveData(rf)
rf1 <- randomForest(SalePrice ~ . , train,
type="regression",
ntree=1000,
do.trace=F)
checkData(rf1)
rf1 <- randomForest(SalePrice ~ MSSubClass + LotFrontage + LotArea + OverallQual +
OverallCond + YearBuilt + YearRemodAdd + MasVnrArea + BsmtFinSF1 +
BsmtUnfSF + X1stFlrSF + X2ndFlrSF + BsmtFullBath + FullBath +
BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + Fireplaces +
GarageCars + WoodDeckSF + X3SsnPorch + ScreenPorch , train,
type="regression",
ntree=100,
do.trace=F)
checkData(rf1)
rf1 <- randomForest(SalePrice ~ MSSubClass + LotFrontage + LotArea + OverallQual +
OverallCond + YearBuilt + YearRemodAdd + MasVnrArea + BsmtFinSF1 +
BsmtUnfSF + X1stFlrSF + X2ndFlrSF + BsmtFullBath + FullBath +
BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + Fireplaces +
GarageCars + WoodDeckSF + X3SsnPorch + ScreenPorch , train,
type="regression",
ntree=1000,
do.trace=F)
checkData(rf1)
watchlist <- list(train=dtrain,test=ctest)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 5,
watchlist = watchlist,
max_depth=6,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
pred_xgb <- predict(xgb,ctest)
RMSE(test_target,pred_xgb)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 5,
watchlist = watchlist,
max_depth=6,
objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
pred_xgb <- predict(xgb,ctest)
RMSE(test_target,pred_xgb)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=6,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 100,
watchlist = watchlist,
max_depth=6,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=6,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=6,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
pred_xgb <- predict(xgb,ctest)
RMSE(test_target,pred_xgb)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 5,
watchlist = watchlist,
max_depth=6,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=100,
maximize = FALSE,
early_stopping_rounds = 5,
watchlist = watchlist,
max_depth=6,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=500,
maximize = FALSE,
early_stopping_rounds = 5,
watchlist = watchlist,
max_depth=6,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=6,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=4,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=3,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
4
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=4,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=4,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=4,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=4,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=4,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.01,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=4,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.02,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=4,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.05,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=4,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.05,
lambda=0.01,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=4,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.05,
lambda=0.05,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=4,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.05,
lambda=0.05,
colsample_bytree=0.7,
subsample = 0.7
)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=4,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.05,
lambda=0.05,
colsample_bytree=0.7,
subsample = 0.8
)
7
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=4,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.05,
lambda=0.05,
colsample_bytree=0.7,
subsample = 0.7
)
RMSE(test_target,pred_xgb)
pred_xgb <- predict(xgb,ctest)
RMSE(test_target,pred_xgb)
#testing this xgboost
a <- data.matrix(select(testing,-SalePrice))
predict(xgb,a)
testing$SalePrice <- predict(xgb,a)
new_data <- data.frame(testing[,"Id"])
new_data$SalePrice <- testing[,"SalePrice"]
write.csv(new_data, "myresult.csv", row.names=FALSE)
rf1 <- randomForest(SalePrice ~ MSSubClass + LotFrontage + LotArea + OverallQual +
OverallCond + YearBuilt + YearRemodAdd + MasVnrArea + BsmtFinSF1 +
BsmtUnfSF + X1stFlrSF + X2ndFlrSF + BsmtFullBath + FullBath +
BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + Fireplaces +
GarageCars + WoodDeckSF + X3SsnPorch + ScreenPorch , train,
type="regression",
ntree=1000,
do.trace=F)
checkData(rf1)
###RandomForest
rf <- randomForest(SalePrice ~., train,
type="classification",
ntree=100,
do.trace=F)
checkData(rf)
saveData(rf)
rf1 <- randomForest(SalePrice ~ MSSubClass + LotFrontage + LotArea + OverallQual +
OverallCond + YearBuilt + YearRemodAdd + MasVnrArea + BsmtFinSF1 +
BsmtUnfSF + X1stFlrSF + X2ndFlrSF + BsmtFullBath + FullBath +
BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + Fireplaces +
GarageCars + WoodDeckSF + X3SsnPorch + ScreenPorch , train,
type="regression",
ntree=1000,
do.trace=F)
checkData(rf1)
##Train Data
train <- read.csv("train.csv")
train <- train %>% mutate_if(is.integer,as.numeric)
nums <- unlist(lapply(train, is.numeric))
t <- train[nums]
index <- createDataPartition(df$SalePrice, p=0.8,list = F)
train <- df[index,]
test <- df[-index,]
###XGBoost
train_matrix <- data.matrix(select(train,-SalePrice))
test_matrix <- data.matrix(select(test,-SalePrice))
train_target <- train$SalePrice
test_target <- test$SalePrice
dtrain <- xgb.DMatrix(data=train_matrix,label=train_target)
ctest <- xgb.DMatrix(data=test_matrix,label=test_target)
watchlist <- list(train=dtrain,test=ctest)
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=4,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.05,
lambda=0.05,
colsample_bytree=0.7,
subsample = 0.7
)
pred_xgb <- predict(xgb,ctest)
RMSE(test_target,pred_xgb)
sum(is.na(train_matrix))
sum(is.na(train))
sum(is.na(t))
df <- t
index <- createDataPartition(df$SalePrice, p=0.8,list = F)
train <- df[index,]
test <- df[-index,]
###XGBoost
train_matrix <- data.matrix(select(train,-SalePrice))
test_matrix <- data.matrix(select(test,-SalePrice))
train_target <- train$SalePrice
test_target <- test$SalePrice
dtrain <- xgb.DMatrix(data=train_matrix,label=train_target)
ctest <- xgb.DMatrix(data=test_matrix,label=test_target)
watchlist <- list(train=dtrain,test=ctest)
sum(is.na(train_matrix))
xgb <- xgb.train(data=dtrain,
nround=1000,
maximize = FALSE,
early_stopping_rounds = 10,
watchlist = watchlist,
max_depth=4,
#objective = "reg:linear",
eval_metric = "rmse",
alpha=0.05,
lambda=0.05,
colsample_bytree=0.7,
subsample = 0.7
)
pred_xgb <- predict(xgb,ctest)
RMSE(test_target,pred_xgb)
sum(is.na(train_matrix))
##Train Data
train <- read.csv("train.csv")
train <- train %>% mutate_if(is.integer,as.numeric)
nums <- unlist(lapply(train, is.numeric))
t <- train[nums]
d <- missForest(t)
##Saving Data
saveData <- function(x){
testing$SalePrice <- predict(rf,testing)
new_data <- data.frame(testing[,"Id"])
new_data$SalePrice <- testing[,"SalePrice"]
write.csv(new_data, "myresult.csv", row.names=FALSE)
}
checkData <- function(x){
pred <- predict(x,test)
print(RMSE(test$SalePrice,pred))
print((summary(x))$adj.r.square)
}
checkDt <- function(x){
pred <- predict(x,test)
print(RMSE(test$SalePrice,pred))
}
###RandomForest
rf <- randomForest(SalePrice ~., train,
type="classification",
ntree=100,
do.trace=F)
pairs(train)
corr.test(train)
